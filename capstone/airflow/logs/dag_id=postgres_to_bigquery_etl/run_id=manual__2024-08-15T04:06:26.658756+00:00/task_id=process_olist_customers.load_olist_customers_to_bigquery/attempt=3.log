[2024-08-16T16:00:02.662+0000] {taskinstance.py:1157} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: postgres_to_bigquery_etl.process_olist_customers.load_olist_customers_to_bigquery manual__2024-08-15T04:06:26.658756+00:00 [queued]>
[2024-08-16T16:00:02.684+0000] {taskinstance.py:1157} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: postgres_to_bigquery_etl.process_olist_customers.load_olist_customers_to_bigquery manual__2024-08-15T04:06:26.658756+00:00 [queued]>
[2024-08-16T16:00:02.684+0000] {taskinstance.py:1359} INFO - Starting attempt 3 of 5
[2024-08-16T16:00:02.720+0000] {taskinstance.py:1380} INFO - Executing <Task(GCSToBigQueryOperator): process_olist_customers.load_olist_customers_to_bigquery> on 2024-08-15 04:06:26.658756+00:00
[2024-08-16T16:00:02.732+0000] {standard_task_runner.py:57} INFO - Started process 332 to run task
[2024-08-16T16:00:02.742+0000] {standard_task_runner.py:84} INFO - Running: ['***', 'tasks', 'run', 'postgres_to_bigquery_etl', 'process_olist_customers.load_olist_customers_to_bigquery', 'manual__2024-08-15T04:06:26.658756+00:00', '--job-id', '648', '--raw', '--subdir', 'DAGS_FOLDER/extract_from_pg.py', '--cfg-path', '/tmp/tmptt1clq8x']
[2024-08-16T16:00:02.747+0000] {standard_task_runner.py:85} INFO - Job 648: Subtask process_olist_customers.load_olist_customers_to_bigquery
[2024-08-16T16:00:02.847+0000] {task_command.py:415} INFO - Running <TaskInstance: postgres_to_bigquery_etl.process_olist_customers.load_olist_customers_to_bigquery manual__2024-08-15T04:06:26.658756+00:00 [running]> on host c04129f4379c
[2024-08-16T16:00:02.941+0000] {warnings.py:109} WARNING - /home/***/.local/lib/python3.8/site-packages/***/utils/context.py:206: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2024-08-16T16:00:03.028+0000] {taskinstance.py:1660} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='postgres_to_bigquery_etl' AIRFLOW_CTX_TASK_ID='process_olist_customers.load_olist_customers_to_bigquery' AIRFLOW_CTX_EXECUTION_DATE='2024-08-15T04:06:26.658756+00:00' AIRFLOW_CTX_TRY_NUMBER='3' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-08-15T04:06:26.658756+00:00'
[2024-08-16T16:00:03.049+0000] {connection.py:232} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2024-08-16T16:00:03.063+0000] {base.py:73} INFO - Using connection ID 'google_cloud_default' for task execution.
[2024-08-16T16:00:03.066+0000] {gcs_to_bigquery.py:375} INFO - Using existing BigQuery table for storing data...
[2024-08-16T16:00:03.178+0000] {gcs_to_bigquery.py:379} INFO - Executing: {'load': {'autodetect': True, 'createDisposition': 'CREATE_IF_NEEDED', 'destinationTable': {'projectId': 'utility-range-425622-c7', 'datasetId': 'olist_ecommerce_data3', 'tableId': 'olist_customers'}, 'sourceFormat': 'NEWLINE_DELIMITED_JSON', 'sourceUris': ['gs://stg-olist-ecommerce-dataset2/data/olist_customers_20240815_040626.json'], 'writeDisposition': 'WRITE_TRUNCATE', 'ignoreUnknownValues': False, 'maxBadRecords': 5}}
[2024-08-16T16:00:03.180+0000] {bigquery.py:1598} INFO - Inserting job ***_postgres_to_bigquery_etl_process_olist_customers_load_olist_customers_to_bigquery_2024_08_15T04_06_26_658756_00_00_40bd4366cf8e973836a1b361101cb9ee
[2024-08-16T16:00:04.430+0000] {taskinstance.py:1935} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 380, in execute
    job: BigQueryJob | UnknownJob = self._submit_job(self.hook, job_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 302, in _submit_job
    return hook.insert_job(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/common/hooks/base_google.py", line 467, in inner_wrapper
    return func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/hooks/bigquery.py", line 1601, in insert_job
    job_api_repr._begin()
  File "/home/airflow/.local/lib/python3.8/site-packages/google/cloud/bigquery/job/base.py", line 693, in _begin
    api_response = client._call_api(
  File "/home/airflow/.local/lib/python3.8/site-packages/google/cloud/bigquery/client.py", line 816, in _call_api
    return call()
  File "/home/airflow/.local/lib/python3.8/site-packages/google/api_core/retry.py", line 349, in retry_wrapped_func
    return retry_target(
  File "/home/airflow/.local/lib/python3.8/site-packages/google/api_core/retry.py", line 191, in retry_target
    return target()
  File "/home/airflow/.local/lib/python3.8/site-packages/google/cloud/_http/__init__.py", line 494, in api_request
    raise exceptions.from_http_response(response)
google.api_core.exceptions.NotFound: 404 POST https://bigquery.googleapis.com/bigquery/v2/projects/utility-range-425622-c7/jobs?prettyPrint=false: Not found: Dataset utility-range-425622-c7:olist_ecommerce_data3
[2024-08-16T16:00:04.450+0000] {taskinstance.py:1398} INFO - Marking task as UP_FOR_RETRY. dag_id=postgres_to_bigquery_etl, task_id=process_olist_customers.load_olist_customers_to_bigquery, execution_date=20240815T040626, start_date=20240816T160002, end_date=20240816T160004
[2024-08-16T16:00:04.480+0000] {standard_task_runner.py:104} ERROR - Failed to execute job 648 for task process_olist_customers.load_olist_customers_to_bigquery (404 POST https://bigquery.googleapis.com/bigquery/v2/projects/utility-range-425622-c7/jobs?prettyPrint=false: Not found: Dataset utility-range-425622-c7:olist_ecommerce_data3; 332)
[2024-08-16T16:00:04.517+0000] {local_task_job_runner.py:228} INFO - Task exited with return code 1
[2024-08-16T16:00:04.637+0000] {taskinstance.py:2776} INFO - 0 downstream tasks scheduled from follow-on schedule check
